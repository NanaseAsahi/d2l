{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f445ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a654c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_blk(num_convs, in_channels, out_channels):\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        in_channels = out_channels\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    \n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f57efa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 256), (2, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc17a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(conv_arch):\n",
    "    in_channels = 1\n",
    "    conv_blks = []\n",
    "    for num_conv, out_channels in conv_arch:\n",
    "        conv_blks.append(vgg_blk(num_conv, in_channels, out_channels))\n",
    "        in_channels = out_channels\n",
    "    \n",
    "    return nn.Sequential(*conv_blks, nn.Flatten(1),\n",
    "                        nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "                        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "                        nn.Linear(4096, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c537c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa82416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blk:Sequential\t output shape:torch.Size([1, 64, 112, 112])\n",
      "blk:Sequential\t output shape:torch.Size([1, 128, 56, 56])\n",
      "blk:Sequential\t output shape:torch.Size([1, 256, 28, 28])\n",
      "blk:Sequential\t output shape:torch.Size([1, 256, 14, 14])\n",
      "blk:Sequential\t output shape:torch.Size([1, 512, 7, 7])\n",
      "blk:Flatten\t output shape:torch.Size([1, 25088])\n",
      "blk:Linear\t output shape:torch.Size([1, 4096])\n",
      "blk:ReLU\t output shape:torch.Size([1, 4096])\n",
      "blk:Dropout\t output shape:torch.Size([1, 4096])\n",
      "blk:Linear\t output shape:torch.Size([1, 4096])\n",
      "blk:ReLU\t output shape:torch.Size([1, 4096])\n",
      "blk:Dropout\t output shape:torch.Size([1, 4096])\n",
      "blk:Linear\t output shape:torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(size=(1, 1, 224, 224))\n",
    "for blk in model:\n",
    "    X = blk(X)\n",
    "    print(f\"blk:{blk.__class__.__name__}\\t output shape:{X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d55eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30beeeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36edce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.FashionMNIST(root=\"../data\", train=True, download=False, transform=transform)\n",
    "test_data = torchvision.datasets.FashionMNIST(root=\"../data\", train=False, download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba0db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=128)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78504f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    if(len(y_hat.shape) > 1 and y_hat.shape[1] > 1):\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    \n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5f3b106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(X.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "312843b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator:\n",
    "    def __init__(self, num):\n",
    "        self.data = [0.0] * num\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "        \n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a9dd0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_acc_gpu(model, test_loader, device=\"cuda\"):\n",
    "    # 放在train函数中使用 故将test_loader中的数据移动到model的参数所在的device上即可\n",
    "    if(isinstance(model, nn.Module)):\n",
    "        model.eval()  # 设置为评估模式\n",
    "        if(device != \"cuda\"):\n",
    "            device = next(model.parameters()).device\n",
    "        \n",
    "        accumulator = Accumulator(2)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X, y in test_loader:\n",
    "                if(isinstance(X, list)):\n",
    "                    X = [x.to(device) for x in X]               \n",
    "                else:\n",
    "                    X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = model(X)\n",
    "            accumulator.add(accuracy(y_hat, y), X.shape[0])\n",
    "    return accumulator[0] / accumulator[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a240763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, num_epochs=10, lr=0.05, device='cuda'):\n",
    "    if device == \"cuda\":\n",
    "        model.to(device)\n",
    "        print(f\"model running in: {next(model.parameters()).device}\")\n",
    "        \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    accumulator = Accumulator(3)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch{epoch+1} start\")\n",
    "        model.train()\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "            y_hat = model(X)\n",
    "            l = loss(y_hat, y)  # 此处二者位置不能更改\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            print(\".\", end=\"\")\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # 累加器中放入每个batch的total loss 准确率 batch_size\n",
    "                accumulator.add(l * X.shape[0], accuracy(y_hat, y), X.shape[0])\n",
    "            \n",
    "            train_l = accumulator[0] / accumulator[2]\n",
    "            train_acc = accumulator[1] / accumulator[2]\n",
    "            \n",
    "        # 使用test_data对model进行eval\n",
    "        test_acc = eval_acc_gpu(model, test_loader)\n",
    "        \n",
    "        print(f\"Epoch{epoch+1}/{num_epochs}\\t train_loss:{train_l}\\t train_acc:{train_acc}\")\n",
    "        print(f\"test_acc:{test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436e12c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model running in: cuda:0\n",
      "Epoch1 start\n",
      "....................................................................................."
     ]
    }
   ],
   "source": [
    "train(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd99eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
